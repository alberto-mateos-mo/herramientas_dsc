# (PART) El argot de ciencia de datos {-}

A pesar de que el mundo de Ciencia de Datos tiene sus fundamentos en estadística y ha heredado de ella un sinfín de conceptos también es cierto que en el contexto de particular de Ciencia de Datos y Machine Learning se han generado conceptos y notación específica que resulta relevante conocer y entender a lo que hace referencia.

# Notación

A lo largo del libro usaremos la notación típica de estadística per también haremos uso de la siguiente:

- $x^{(i)}$: el conjunto de inputs (variables explicativas)
- $y^{(i)}$: es la variable de output/salida (variable dependiente) que queremos predecir (ajustar)
- A la pareja $(x^{(i)},y^{(i)})$ le llamaremos ejemplo de entrenamiento
- El conjunto de entrenamiento se denota por: $\{(x^{(i)},y^{(i)})|i\in N\}$
- De forma general, denotaremos por $\mathcal{X}$ al espacio de inputs y por $\mathcal{Y}$ al espacio de outputs

N.B. Omitiremos el uso de indices en donde sea claro a qué nos referimos.

# Glosario DSc/ML - Estadística

|         Machine Learning / Ciencia de Datos        |                Estadística               |
|:--------------------------------------------------:|:----------------------------------------:|
|            red, grafo (network, graphs)            |              modelo (model)              |
|                   pesos (weigths)                  |          parámetros (parameters)         |
|               aprendizaje (learning)               |              ajuste (fiting)             |
|  prueba, generalización (testing, generalization)  |      ajuste en el conjunto de prueba     |
|    aprendizaje supervisado (supervised learning)   |         regresión, clasificación         |
| aprendizaje no supervisado (unsupervised learning) | estimación de densidades, clusterización |

# Entrenamiento de modelos

Se le denomina de esta manera a la acción de ajustar el _mejor_ modelo a los datos.

Formalmente se define como sigue:

Dado un conjunto de entrenamiento $(x^{(i)},y^{(i)})\in(\mathcal{X} \times \mathcal{Y})$ el objetivo es "aprender" (ajustar) una función $h:\mathcal{X}\rightarrow \mathcal{Y}$ tal que $h(x)$ sea un "buen predictor" de $y$.

La función $h$ suele llamarse "hipótesis".

Cuando el conjunto $\mathcal{Y}$ es continuo, estamos frente a un problema de regresión. Si se trata de un conjunto discreto* entonces tenemos un problema de clasificación.